## Step 2 - Prepare the data
```{r}
library(tidyverse)
rfdata <- accdata2012_2014 %>%
  na.omit() %>%
    select(loan_status,loan_amnt,funded_amnt,term,int_rate,installment,home_ownership,annual_inc,verification_status,open_acc,total_pymnt)

str(rfdata)
set.seed(999)
indx <- sample(1:nrow(rfdata),as.integer(0.75*nrow(rfdata)))
rfdata_train <- rfdata[indx,]
rfdata_test <- rfdata[-indx,]

rfdata_train_labels <- rfdata[indx,1,drop = TRUE]
rfdata_test_labels <- rfdata[-indx,1,drop = TRUE]
dim(rfdata_train)
dim(rfdata_test)
dim(rfdata_train_labels)
dim(rfdata_test_labels)
```

## Step 3 – training a model on the data
```{r}
library(randomForest)
library(gmodels)
ranf_model <- randomForest(loan_status ~ . , data = rfdata_train, ntree = 201, mtry = 5)
summary(ranf_model)
varImpPlot(ranf_model)
```

## Step 4 – evaluating model performance
```{r}
ranf_pred <- predict(ranf_model, rfdata_test)

CrossTable(ranf_pred, rfdata_test$loan_status, prop.chisq = FALSE, prop.t = FALSE, prop.r = FALSE, dnn = c('predicted', 'actual'))
misClasificError <- mean(ranf_pred != rfdata_test$loan_status,na.rm = TRUE)
print(paste('Accuracy',1-misClasificError))

# ROC
library(ROCR)
pr_ranf <- prediction(as.numeric(ranf_pred), rfdata_test$loan_status)
prf.ranf <- performance(pr_ranf, measure = "tpr", x.measure = "fpr")
plot(prf.ranf)
auc <- performance(pr_ranf, measure = "auc")
auc.ranf <- auc@y.values[[1]]
auc.ranf
```

